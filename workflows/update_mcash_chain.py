"""
Job controller module (update_mcash_chain) controls the order of execution
of the specialized modules implemented in the ``tasks`` package, which consists of:\n
1. A video dump file capture and web automation scraper\n
2. A photo set source code capture with web automation scraping\n
3. A txt file parser and SQLite database generator.\n
4. An HTML source parser and SQLite database generator.\n

This job control module also includes certain validation steps that make it less
likely to fail in each of the jobs.\m

*** Steps to update the databases from MongerCash ***
(if I were to do it without a centralised job controller)\n
1. Get the dump and source files separately to create the photosets and vid databases.\n
2. Call the parsing modules on the text dump and HTML sources separately.\n
3. Clean the temporary files generated by the entire process.\n
4. Clean outdated files that previous iterations of this process generate.\n

There is a missing step: clean outdated files to avoid file accumulation in the project
directory. There is another workflow in this package that can do it, however, I want to
run the ``clean_outdated_files`` module manually in case I want to check the new and old files.
In my main workflow, I include this step in a bash script that calls ``clean_outdated_files.py``
from this package.

Author: Yoham Gabriel Urbine@GitHub
Email: yohamg@programmer.net

"""

__author__ = "Yoham Gabriel Urbine@GitHub"
__author_email__ = "yohamg@programmer.net"

import argparse
import sqlite3
import warnings
import tempfile

# Local implementations
from core import (
    is_parent_dir_required,
    get_webdriver,
    load_from_file,
    clean_filename,
    remove_if_exists,
)

from tasks.mcash_dump_create import get_vid_dump_flow
from tasks.mcash_scrape import get_set_source_flow
from tasks.parse_txt_dump import parse_txt_dump_chain
from tasks.sets_source_parse import db_generate


if __name__ == "__main__":
    print("Welcome to the MongerCash local update wizard")

    arg_parser = argparse.ArgumentParser(
        description="mcash local update wizard arguments"
    )

    arg_parser.add_argument(
        "--hint",
        type=str,
        help="This parameter receives the first word of the partner offer for matching",
    )

    arg_parser.add_argument(
        "--parent",
        action="store_true",
        help="Set if you want the resulting files to be located in the parent dir.",
    )

    arg_parser.add_argument(
        "--gecko", action="store_true", help="Use the Gecko webdriver for this process."
    )

    arg_parser.add_argument(
        "--headless", action="store_true", help="Browser headless execution."
    )

    arg_parser.add_argument(
        "--silent", action="store_true", help="Ignore user warnings"
    )

    args = arg_parser.parse_args()

    if args.silent:
        warnings.filterwarnings("ignore")
    else:
        pass

    webdriver = get_webdriver("", headless=args.headless, gecko=args.gecko)

    # Fetching
    temp_dir, dump_file_name = get_vid_dump_flow(
        webdriver,
        partner_hint=args.hint,
    )

    # Test if the file contains characters and it is not empty.
    # If the file is empty, it means that something went wrong with the
    # webdriver.
    load_dump_file = load_from_file(
        dump_file_name, "txt", dirname=temp_dir.name, parent=None
    )
    while len(load_dump_file) == 0:
        warnings.warn("The content of the dump file is empty, retrying...", UserWarning)
        temp_dir, dump_file_name = get_vid_dump_flow(
            webdriver,
            partner_hint=args.hint,
        )
        load_dump_file = load_from_file(
            dump_file_name, "txt", dirname=temp_dir.name, parent=None
        )
        continue

    # webdriver gets a second assignment to avoid connection pool issues.
    webdriver = get_webdriver(temp_dir.name, headless=args.headless, gecko=args.gecko)
    photoset_source = get_set_source_flow(webdriver, partner_hint=args.hint)

    # Just like the text dump, the source code could be empty and I need to
    # test it.
    while len(photoset_source[0]) == 0:
        warnings.warn("The source file is empty, retrying...", UserWarning)
        photoset_source = get_set_source_flow(webdriver, partner_hint=args.hint)
        continue

    # Parsing video txt dump:

    db_name = clean_filename(dump_file_name, "db")
    remove_if_exists(db_name)
    db_conn = sqlite3.connect(f"{is_parent_dir_required(parent=args.parent)}{db_name}")
    cursor = db_conn.cursor()
    cursor.execute(
        """
    CREATE TABLE
        videos(
        title,
        description,
        model,
        tags,
        date,
        duration,
        source_url,
        thumbnail_url,
        tracking_url,
        wp_slug
        )
    """
    )

    parsing = parse_txt_dump_chain(
        dump_file_name,
        db_name,
        db_conn,
        cursor,
        dirname=temp_dir.name,
        parent=args.parent,
    )
    print(
        f"{parsing[1]} video entries have been processed from {dump_file_name} and inserted into\n{parsing[0]}\n"
    )

    parsing_photos = db_generate(
        photoset_source[0], photoset_source[1], parent=args.parent
    )
    print(
        f"{parsing_photos[1]} photo set entries have been processed and inserted into\n{parsing_photos[0]}\n"
    )

    # Tidy up
    print(f"Cleaning temporary directory {temp_dir.name}")
    temp_dir.cleanup()
